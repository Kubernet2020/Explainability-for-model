{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NBDT_command_line.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZDlAguZpOl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3657fd23-d62b-4eab-96f6-ac85bcbcf2ce"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount( '/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwYtaDPYpbmP"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/gdrive/My Drive/NBDT_env\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8ydzMgopxsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d939e72-7f4b-4b8a-d133-80322179e6b3"
      },
      "source": [
        "!git clone https://github.com/alvinwan/neural-backed-decision-trees.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'neural-backed-decision-trees'...\n",
            "remote: Enumerating objects: 3559, done.\u001b[K\n",
            "remote: Counting objects: 100% (3559/3559), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1219/1219), done.\u001b[K\n",
            "remote: Total 3559 (delta 2388), reused 3445 (delta 2278), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3559/3559), 2.46 MiB | 2.35 MiB/s, done.\n",
            "Resolving deltas: 100% (2388/2388), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1HcHXxdqNrU"
      },
      "source": [
        "import os \n",
        "os.chdir(\"/gdrive/My Drive/NBDT_env/neural-backed-decision-trees\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLrhinSFrNnl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b948245-926a-4b57-a25c-ab0661f83bc8"
      },
      "source": [
        "#change requirment torch 0.4.0 to 0.6.0\n",
        "%%shell\n",
        "pip install pytorchcv"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorchcv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/a8/2eca120c1ac44730ac3f36547f405536f3da66674940deb94ae4b457cd7c/pytorchcv-0.0.60-py2.py3-none-any.whl (465kB)\n",
            "\r\u001b[K     |▊                               | 10kB 5.5MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 7.6MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 5.6MB/s eta 0:00:01\r\u001b[K     |██▉                             | 40kB 2.8MB/s eta 0:00:01\r\u001b[K     |███▌                            | 51kB 3.4MB/s eta 0:00:01\r\u001b[K     |████▏                           | 61kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 71kB 4.2MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 81kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 133kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 143kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 153kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 163kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 174kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 184kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 194kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 204kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 215kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 225kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 235kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 245kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 256kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 266kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 276kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 286kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 296kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 307kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 317kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 327kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 337kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 348kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 358kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 368kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 378kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 389kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 399kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 409kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 419kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 430kB 4.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 440kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 450kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 460kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 471kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorchcv) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorchcv) (1.18.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorchcv) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorchcv) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorchcv) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorchcv) (2020.12.5)\n",
            "Installing collected packages: pytorchcv\n",
            "Successfully installed pytorchcv-0.0.60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbLLOnAsNB6O"
      },
      "source": [
        " !chmod -R 755 ."
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztuy2DIONZLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8f2d6c6-d7f3-4c49-9c35-c6bc12211cc4"
      },
      "source": [
        "!pip install nbdt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nbdt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/3a/75fb13e538bb75df5bb4802a7296311e88923eec0c1f76e9da5e2887f6b9/nbdt-0.0.4.tar.gz (119kB)\n",
            "\r\u001b[K     |██▊                             | 10kB 23.2MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 20kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 30kB 8.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 40kB 7.3MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 81kB 5.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 92kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 102kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 112kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytorchcv in /usr/local/lib/python3.6/dist-packages (from nbdt) (0.0.60)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from nbdt) (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from nbdt) (0.8.1+cu101)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from nbdt) (3.2.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from nbdt) (0.22.2.post1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from nbdt) (2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorchcv->nbdt) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorchcv->nbdt) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->nbdt) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->nbdt) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->nbdt) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->nbdt) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->nbdt) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->nbdt) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->nbdt) (1.4.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->nbdt) (4.4.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorchcv->nbdt) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorchcv->nbdt) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorchcv->nbdt) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorchcv->nbdt) (2020.12.5)\n",
            "Building wheels for collected packages: nbdt\n",
            "  Building wheel for nbdt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nbdt: filename=nbdt-0.0.4-cp36-none-any.whl size=132323 sha256=d8171bfe6b460ff622e9e0852a862a753540f096675ed09888aae2a5b5af12de\n",
            "  Stored in directory: /root/.cache/pip/wheels/24/42/99/f41adfed4f1250366d8add49449d06ca7583043684e3a3f4bd\n",
            "Successfully built nbdt\n",
            "Installing collected packages: nbdt\n",
            "Successfully installed nbdt-0.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkjhFtGUrUdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ce63451-801f-4fc3-fc53-309ffc25ebb5"
      },
      "source": [
        "!nbdt-hierarchy --arch=wrn28_10_cifar10 --dataset=CIFAR10"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "**********************************************************************\n",
            "  Resource \u001b[93mwordnet\u001b[0m not found.\n",
            "  Please use the NLTK Downloader to obtain the resource:\n",
            "\n",
            "  \u001b[31m>>> import nltk\n",
            "  >>> nltk.download('wordnet')\n",
            "  \u001b[0m\n",
            "  Searched in:\n",
            "    - '/root/nltk_data'\n",
            "    - '/usr/share/nltk_data'\n",
            "    - '/usr/local/share/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "    - '/usr/local/lib/nltk_data'\n",
            "    - '/usr/nltk_data'\n",
            "    - '/usr/lib/nltk_data'\n",
            "**********************************************************************\n",
            "\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "Ignoring TypeError. Retrying without `dataset` kwarg: __init__() got an unexpected keyword argument 'dataset'\n",
            "Downloading /root/.torch/models/wrn28_10_cifar10-0239-fe97dcd6.pth.zip from https://github.com/osmr/imgclsmob/releases/download/v0.0.166/wrn28_10_cifar10-0239-fe97dcd6.pth.zip...\n",
            "[matched] \t Nodes: 19 \t Depth: 5 \t Max Children: 9\n",
            "[pruned] \t Nodes: 19 \t Depth: 5 \t Max Children: 9\n",
            "\u001b[32m==> Wrote tree to ./nbdt/hierarchies/CIFAR10/graph-induced-wrn28_10_cifar10.json \u001b[0m\n",
            "==> Reading from ./nbdt/hierarchies/CIFAR10/graph-induced-wrn28_10_cifar10.json\n",
            "[graph-induced-wrn28_10_cifar10] \t leaves: 10 \t WNIDs missing from leaves: 0\n",
            "[graph-induced-wrn28_10_cifar10] \t nodes: 19 \t WNIDs missing from nodes: 0\n",
            "\u001b[32mFound just 1 root. \u001b[0m\n",
            "\u001b[32m==> All checks pass! \u001b[0m\n",
            "==> Reading from ./nbdt/hierarchies/CIFAR10/graph-induced-wrn28_10_cifar10.json\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "100% 170237952/170498071 [00:11<00:00, 16758694.11it/s]Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Found just 1 root.\n",
            "\u001b[32m==> Wrote HTML to out/CIFAR10-induced-wrn28_10_cifar10-tree.html \u001b[0m\n",
            "170500096it [00:15, 11095625.75it/s]                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DL1X83BOIZ3"
      },
      "source": [
        "#change main.py epoch to 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOjLLciTrdf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c651ca2e-4fbb-451f-f52e-f1d249e76acb"
      },
      "source": [
        "!python main.py --lr=0.01 --dataset=CIFAR10 --arch=wrn28_10_cifar10 --hierarchy=induced-wrn28_10_cifar10 --pretrained --loss=SoftTreeSupLoss"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\u001b[36mTraining with dataset CIFAR10 and 10 classes \u001b[0m\n",
            "==> Building model..\n",
            "==> Loading pretrained model..\n",
            "__init__() got an unexpected keyword argument 'dataset'\n",
            "==> Checkpoints will be saved to: ./checkpoint/ckpt-CIFAR10-wrn28_10_cifar10-induced-wrn28_10_cifar10-SoftTreeSupLoss.pth\n",
            "\u001b[36mpath_graph:\t/gdrive/MyDrive/NBDT_env/neural-backed-decision-trees/nbdt/hierarchies/CIFAR10/graph-induced-wrn28_10_cifar10.json \u001b[0m\n",
            "\u001b[36mpath_wnids:\t/gdrive/MyDrive/NBDT_env/neural-backed-decision-trees/nbdt/wnids/CIFAR10.txt \u001b[0m\n",
            "\u001b[36mtree_supervision_weight:\t1 \u001b[0m\n",
            "\u001b[36mclasses:\t(callable) \u001b[0m\n",
            "\u001b[36mdataset:\t(callable) \u001b[0m\n",
            "\u001b[36mcriterion:\t(callable) \u001b[0m\n",
            "\u001b[36mclasses:\t(callable) \u001b[0m\n",
            "\n",
            "Epoch: 0\n",
            " [================================================================>]  Step: 3s422ms | Tot: 1m53s | Loss: 1.510 | Acc: 100.000% (50000/50000)  98/98 \n",
            " [================================================================>]  Step: 80ms | Tot: 8s84ms | Loss: 1.606 | Acc: 97.530% (9753/10000)  100/100 \n",
            "Accuracy: 97.53, 9753/10000\n",
            "Saving to ckpt-CIFAR10-wrn28_10_cifar10-induced-wrn28_10_cifar10-SoftTreeSupLoss (97.53)..\n",
            "\n",
            "Epoch: 1\n",
            " [================================================================>]  Step: 756ms | Tot: 1m50s | Loss: 1.484 | Acc: 99.998% (49999/50000)  98/98 \n",
            " [================================================================>]  Step: 82ms | Tot: 8s78ms | Loss: 1.603 | Acc: 97.580% (9758/10000)  100/100 \n",
            "Accuracy: 97.58, 9758/10000\n",
            "Saving to ckpt-CIFAR10-wrn28_10_cifar10-induced-wrn28_10_cifar10-SoftTreeSupLoss (97.58)..\n",
            "\n",
            "Epoch: 2\n",
            " [================================================================>]  Step: 781ms | Tot: 1m50s | Loss: 1.479 | Acc: 99.998% (49999/50000)  98/98 \n",
            " [================================================================>]  Step: 80ms | Tot: 8s45ms | Loss: 1.602 | Acc: 97.600% (9760/10000)  100/100 \n",
            "Accuracy: 97.6, 9760/10000\n",
            "Saving to ckpt-CIFAR10-wrn28_10_cifar10-induced-wrn28_10_cifar10-SoftTreeSupLoss (97.6)..\n",
            "\n",
            "Epoch: 3\n",
            " [================================================================>]  Step: 764ms | Tot: 1m50s | Loss: 1.476 | Acc: 100.000% (50000/50000)  98/98 \n",
            " [================================================================>]  Step: 80ms | Tot: 8s55ms | Loss: 1.603 | Acc: 97.610% (9761/10000)  100/100 \n",
            "Accuracy: 97.61, 9761/10000\n",
            "Saving to ckpt-CIFAR10-wrn28_10_cifar10-induced-wrn28_10_cifar10-SoftTreeSupLoss (97.61)..\n",
            "\n",
            "Epoch: 4\n",
            " [================================================================>]  Step: 777ms | Tot: 1m50s | Loss: 1.473 | Acc: 100.000% (50000/50000)  98/98 \n",
            " [================================================================>]  Step: 79ms | Tot: 8s40ms | Loss: 1.604 | Acc: 97.570% (9757/10000)  100/100 \n",
            "Accuracy: 97.57, 9757/10000\n",
            "\n",
            "Epoch: 5\n",
            " [================================================================>]  Step: 774ms | Tot: 1m50s | Loss: 1.472 | Acc: 99.996% (49998/50000)  98/98 \n",
            " [================================================================>]  Step: 80ms | Tot: 8s28ms | Loss: 1.604 | Acc: 97.590% (9759/10000)  100/100 \n",
            "Accuracy: 97.59, 9759/10000\n",
            "\n",
            "Epoch: 6\n",
            " [================================================================>]  Step: 772ms | Tot: 1m50s | Loss: 1.472 | Acc: 100.000% (50000/50000)  98/98 \n",
            " [================================================================>]  Step: 80ms | Tot: 8s50ms | Loss: 1.604 | Acc: 97.610% (9761/10000)  100/100 \n",
            "Accuracy: 97.61, 9761/10000\n",
            "\n",
            "Epoch: 7\n",
            " [================================================================>]  Step: 756ms | Tot: 1m50s | Loss: 1.472 | Acc: 100.000% (50000/50000)  98/98 \n",
            " [================================================================>]  Step: 80ms | Tot: 8s56ms | Loss: 1.604 | Acc: 97.570% (9757/10000)  100/100 \n",
            "Accuracy: 97.57, 9757/10000\n",
            "\n",
            "Epoch: 8\n",
            " [================================================================>]  Step: 773ms | Tot: 1m50s | Loss: 1.472 | Acc: 100.000% (50000/50000)  98/98 \n",
            " [================================================================>]  Step: 80ms | Tot: 8s32ms | Loss: 1.604 | Acc: 97.580% (9758/10000)  100/100 \n",
            "Accuracy: 97.58, 9758/10000\n",
            "\n",
            "Epoch: 9\n",
            " [================================================================>]  Step: 761ms | Tot: 1m50s | Loss: 1.472 | Acc: 99.996% (49998/50000)  98/98 \n",
            " [================================================================>]  Step: 79ms | Tot: 8s47ms | Loss: 1.604 | Acc: 97.560% (9756/10000)  100/100 \n",
            "Accuracy: 97.56, 9756/10000\n",
            "Best accuracy: 97.61 // Checkpoint name: ckpt-CIFAR10-wrn28_10_cifar10-induced-wrn28_10_cifar10-SoftTreeSupLoss\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHYNAXYEEWWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b6c3df7-9f03-45a1-d589-5bbf038e4550"
      },
      "source": [
        "!python main.py --dataset=CIFAR10 --arch=wrn28_10_cifar10 --hierarchy=induced-wrn28_10_cifar10 --loss=SoftTreeSupLoss --eval --resume --analysis=SoftEmbeddedDecisionRules"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "\u001b[36mTraining with dataset CIFAR10 and 10 classes \u001b[0m\n",
            "==> Building model..\n",
            "==> Checkpoints will be saved to: ./checkpoint/ckpt-CIFAR10-wrn28_10_cifar10-induced-wrn28_10_cifar10-SoftTreeSupLoss.pth\n",
            "==> Resuming from checkpoint..\n",
            "\u001b[36m==> Checkpoint found for epoch 3 with accuracy 97.61 at ./checkpoint/ckpt-CIFAR10-wrn28_10_cifar10-induced-wrn28_10_cifar10-SoftTreeSupLoss.pth \u001b[0m\n",
            "\u001b[36mpath_graph:\t/gdrive/MyDrive/NBDT_env/neural-backed-decision-trees/nbdt/hierarchies/CIFAR10/graph-induced-wrn28_10_cifar10.json \u001b[0m\n",
            "\u001b[36mpath_wnids:\t/gdrive/MyDrive/NBDT_env/neural-backed-decision-trees/nbdt/wnids/CIFAR10.txt \u001b[0m\n",
            "\u001b[36mtree_supervision_weight:\t1 \u001b[0m\n",
            "\u001b[36mclasses:\t(callable) \u001b[0m\n",
            "\u001b[36mdataset:\t(callable) \u001b[0m\n",
            "\u001b[36mcriterion:\t(callable) \u001b[0m\n",
            "\u001b[36mpath_graph:\t/gdrive/MyDrive/NBDT_env/neural-backed-decision-trees/nbdt/hierarchies/CIFAR10/graph-induced-wrn28_10_cifar10.json \u001b[0m\n",
            "\u001b[36mpath_wnids:\t/gdrive/MyDrive/NBDT_env/neural-backed-decision-trees/nbdt/wnids/CIFAR10.txt \u001b[0m\n",
            "\u001b[36mclasses:\t(callable) \u001b[0m\n",
            "\u001b[36mdataset:\t(callable) \u001b[0m\n",
            " [================================================================>]  Step: 82ms | Tot: 8s397ms | Loss: 1.603 | Acc: 97.610% (9761/10000) | NBDT-Soft: 97.49% 100/100 \n",
            "Accuracy: 97.61, 9761/10000\n",
            "NBDT-Soft Accuracy: 97.49%, 9749/10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhjnEdoyOxI6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}